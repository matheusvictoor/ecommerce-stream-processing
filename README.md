# ğŸ›’ E-commerce Real-Time Stream Processing

**Disciplina**: Arquitetura de Software \
**Curso**: CiÃªncia da ComputaÃ§Ã£o \
**InstituiÃ§Ã£o**: Universidade Federal de Campina Grande - UFCG

## ğŸ“Œ VisÃ£o Geral
Este projeto implementa uma pipeline completa de processamento de stream em tempo real para anÃ¡lise de transaÃ§Ãµes de e-commerce. A arquitetura segue os princÃ­pios de desacoplamento, escalabilidade, observabilidade e resiliÃªncia, utilizando tecnologias modernas de streaming e armazenamento.

- A pipeline simula transaÃ§Ãµes de compras, as processa em janelas de 1 minuto, agrega mÃ©tricas de vendas e persiste os resultados em dois sistemas distintos:

- PostgreSQL para armazenamento transacional e consultas SQL
Elasticsearch + Kibana para visualizaÃ§Ã£o interativa e anÃ¡lise em tempo real

## ğŸ—ï¸ Arquitetura da SoluÃ§Ã£o
![alt text](architecture.png)

### Componentes

|  COMPONENTE         |                         FUNCÃ‚O                                 |
|---------------------|----------------------------------------------------------------|
| **Locust**          | Gera carga simulando usuÃ¡rios reais (transaÃ§Ãµes de compra)     |
| **Producer**        | API REST (Flask) que recebe transaÃ§Ãµes e envia para o Kafka    |
| **Kafka**           | Sistema de mensageria distribuÃ­do (tÃ³pico: transactions)       |
| **Zookeeper**       | CoordenaÃ§Ã£o do cluster Kafka (obrigatÃ³rio na versÃ£o 7.4 usada) |
| **Flink**           | Motor de processamento de stream (JobManager + TaskManager)    |
| **PostgreSQL**      | Banco relacional para armazenamento estruturado                |
| **Elasticsearch**   | Motor de busca/anÃ¡lise para dados nÃ£o estruturado              |
| **Kibana**          | Interface de visualizaÃ§Ã£o e dashboard                          |
| **Kafka UI**        | Interface web para monitoramento de tÃ³picos e mensagens        |


## ğŸ“¦ Estrutura do Projeto
```
ECOMMERCE-STREAM-PROCESSING/
â”œâ”€Â README.md
â”œâ”€Â architecture.png
â”œâ”€Â docker-compose.yml
â”œâ”€Â elasticsearch
â”‚Â Â â””â”€Â templates
â”‚Â Â Â Â Â â””â”€Â transaction_template.json
â”œâ”€Â flink-job
â”‚Â Â â”œâ”€Â Dockerfile
â”‚Â Â â”œâ”€Â SalesAggregationJob.py
â”‚Â Â Â Â Â â”œâ”€Â flink-connector-jdbc-3.1.2-1.18.jar
â”‚Â Â Â Â Â â”œâ”€Â flink-connector-kafka-3.0.1-1.18.jar
â”‚Â Â Â Â Â â”œâ”€Â flink-sql-connector-elasticsearch7-3.1.0-1.18.jar
â”‚Â Â Â Â Â â”œâ”€Â kafka-clients-3.4.0.jar
â”‚Â Â Â Â Â â””â”€Â postgresql-42.6.0.jar
â”œâ”€Â kibana
â”‚Â Â â””â”€Â kibana.yml
â”œâ”€Â locust
â”‚Â Â â”œâ”€Â Dockerfile
â”‚Â Â â””â”€Â locustfile.py
â”œâ”€Â postgres
â”‚Â Â â””â”€Â init.sql
â”œâ”€Â producer
â”‚Â Â â”œâ”€Â Dockerfile
â”‚Â Â â”œâ”€Â producer.py
â”‚Â Â â””â”€Â requirements.txt
â”œâ”€Â scripts
â”‚Â Â â””â”€Â start-all.sh
â””â”€Â tests
Â Â Â â””â”€Â load_test.sh
```


## ğŸš€ Tecnologias

- Apache Flink
- Kafka
- Locust
- PostgreSQL
- Elasticsearch + Kibana
- Docker + Docker Compose
- GitHub Actions (CI/CD)

## â–¶ï¸ Como Executar
PrÃ©-requisitos
- Docker e Docker Compose instalados
- Acesso Ã  internet (para baixar imagens e JARs)

Passo a passo

1. Baixar os conectores necessÃ¡rios (faÃ§a isso uma vez):
```bash
# Na pasta raiz do projeto
mkdir -p flink-job/lib

# Conector JDBC
wget https://repo1.maven.org/maven2/org/apache/flink/flink-connector-jdbc/3.1.2-1.18/flink-connector-jdbc-3.1.2-1.18.jar -P flink-job/lib/

# Conector Elasticsearch 7
wget https://repo1.maven.org/maven2/org/apache/flink/flink-sql-connector-elasticsearch7/3.1.0-1.18/flink-sql-connector-elasticsearch7-3.1.0-1.18.jar -P flink-job/lib/

# Driver JDBC do PostgreSQL
wget https://jdbc.postgresql.org/download/postgresql-42.6.0.jar -P flink-job/lib/
```

2. Iniciar toda a stack:
```bash
chmod +x scripts/*.sh
./scripts/start-all.sh
```

3. Acessar os serviÃ§os:

|    SERVIÃ‡O          |                    URL                   |
|---------------------|------------------------------------------|
| **Locust**          |     http://localhost:8089                |
| **Kafka UI**        |     http://localhost:8080                |
| **Flink Web UI**    |     http://localhost:8081                |
| **Kibana**          |     http://localhost:5601                |

4. (Opcional) Executar teste de carga manual:
```bash
./scripts/load_test.sh
```

## âœ… ValidaÃ§Ã£o da Pipeline

Ele verifica:

- Se hÃ¡ dados na tabela sales_summary do PostgreSQL
- Se hÃ¡ documentos no Ã­ndice transactions-aggregated do Elasticsearch
- Se o Kibana estÃ¡ respondendo

Resultado esperado: ğŸ‰ **PIPELINE VALIDADA COM SUCESSO!**


## ğŸ“Š VisualizaÃ§Ã£o no Kibana
1. Acesse http://localhost:5601

2. VÃ¡ em Stack Management â†’ Data Views â†’ Create data view
    - Name: transactions-*
    - Index pattern: transactions-*
    - Timestamp field: @timestamp
3. VÃ¡ em Analytics â†’ Discover e explore os dados

4. Crie dashboards com:
    - Receita total por categoria
    - Vendas por mÃ©todo de pagamento
    - EvoluÃ§Ã£o temporal de vendas

## ğŸ§ª Testes Automatizados

Na raiz do projeto, rode o seguinte comando para rodar os testes:
```bash
./tests/load_test.sh
python tests/validate_pipeline.py
```

## ğŸ› ï¸ Tecnologias Utilizadas

|      CATEGORIA           |           TECNOLOGIA        |  VERSÃ‚O  |
|--------------------------|-----------------------------|----------|
| **Mensageria**           | Apache Kafka + Zookeeper    | 7.4.0    |
| **Processamento**        | Apache Flink (PyFlink)      | 1.18.1   |
| **Armazenamento**        | PostgreSQL                  | 17       |
| **Busca/VisualizaÃ§Ã£o**   | Elasticsearch + Kibana      | 8.11.0   | 
| **GeraÃ§Ã£o de Carga**     | Locust                      | 2.25.0   |
| **API**                  | Flask                       | 2.3.3    |
| **OrquestraÃ§Ã£o**         | Docker Compose              |    --    |


## ğŸ‘¥ Contribuidores
- Matheus Victor Pereira
- Aline de Brito das Neves
- Johansson Lucena
- Igor Ribeiro de Souza
- Erick Araken Vieira Gomes


## ğŸ“š ReferÃªncias
- Apache Flink Documentation: https://nightlies.apache.org/flink/flink-docs-release-1.18/
- Elasticsearch + Flink Connector: https://nightlies.apache.org/flink/flink-docs-release-1.18/docs/connectors/datastream/elasticsearch/
- Locust: https://locust.io/
- Kafka UI: https://github.com/kafbat/kafka-ui